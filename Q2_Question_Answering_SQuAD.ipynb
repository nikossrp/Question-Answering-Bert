{"cells":[{"cell_type":"markdown","metadata":{"id":"Y4t41SqfyFU_"},"source":["# Import necessary libraries and set seeds"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:10:38.304864Z","iopub.status.busy":"2022-03-05T16:10:38.304325Z","iopub.status.idle":"2022-03-05T16:10:38.361950Z","shell.execute_reply":"2022-03-05T16:10:38.361187Z","shell.execute_reply.started":"2022-03-05T16:10:38.304824Z"},"executionInfo":{"elapsed":7021,"status":"ok","timestamp":1646313157999,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"cRLV184nD09M","outputId":"c462e213-112b-4c12-e573-4585a65137c4","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Working on: cuda\n"]}],"source":["import torch\n","from tqdm.notebook import tqdm\n","\n","# from transformers import BertTokenizer\n","# from torch.utils.data import TensorDataset\n","# from transformers import BertForSequenceClassification\n","\n","# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n","import logging\n","#logging.basicConfig(level=logging.INFO)\n","\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import random\n","import numpy as np\n","import os\n","import time # time module \n","\n","import json\n","\n","\n","\n","def set_seed(seed = 1234):\n","    '''Sets the seed of the entire notebook so results are the same every time we run.\n","    This is for REPRODUCIBILITY.'''\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    # When running on the CuDNN backend, two further options must be set\n","    torch.backends.cudnn.deterministic = True\n","    # Set a fixed value for the hash seed\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    \n","set_seed(23456)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # use 'cuda' if available else 'cpu'\n","print('Working on:', device)"]},{"cell_type":"markdown","metadata":{"id":"9r9nl83L6DUB"},"source":["# Download Squad2.0"]},{"cell_type":"markdown","metadata":{"id":"tTIMcUKn6Js6"},"source":["We have already downloaded the datasets from https://rajpurkar.github.io/SQuAD-explorer/ in our drive"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:10:40.824314Z","iopub.status.busy":"2022-03-05T16:10:40.823913Z","iopub.status.idle":"2022-03-05T16:10:40.828763Z","shell.execute_reply":"2022-03-05T16:10:40.827942Z","shell.execute_reply.started":"2022-03-05T16:10:40.824271Z"},"executionInfo":{"elapsed":237,"status":"ok","timestamp":1646313181255,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"rP6GGdSn6hi9","trusted":true},"outputs":[],"source":["Location_squad_train2 = '../input/squad-20/train-v2.0.json'\n","Location_squad_dev2 = '../input/squad-20/dev-v2.0.json'"]},{"cell_type":"markdown","metadata":{"id":"a--Qcnqb8rA0"},"source":["# Prepare train and test set"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:10:42.365657Z","iopub.status.busy":"2022-03-05T16:10:42.365071Z","iopub.status.idle":"2022-03-05T16:10:42.374543Z","shell.execute_reply":"2022-03-05T16:10:42.373835Z","shell.execute_reply.started":"2022-03-05T16:10:42.365616Z"},"executionInfo":{"elapsed":267,"status":"ok","timestamp":1646313183942,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"S2YSvtZj8Pcd","trusted":true},"outputs":[],"source":["# if num_groups=-1 we will take all the dataset, \n","# or we will take the selected number of groups\n","\n","def read_squad(path, num_groups=-1):\n","    # open JSON file and load intro dictionary\n","    with open(path, 'rb') as f:\n","        squad_dict = json.load(f)\n","\n","    # initialize lists for contexts, questions, and answers\n","    contexts = []\n","    questions = []\n","    answers = []\n","    # iterate through all data in squad data\n","    for group in squad_dict['data']:\n","        if num_groups <= 0 and num_groups != -1:   \n","          break \n","        for passage in group['paragraphs']:\n","            context = passage['context']\n","            for qa in passage['qas']:\n","                question = qa['question']\n","                # check if we need to be extracting from 'answers' or 'plausible_answers'\n","                if 'plausible_answers' in qa.keys():\n","                    access = 'plausible_answers'\n","                else:\n","                    access = 'answers'\n","                for answer in qa[access]:\n","                    # append data to lists\n","                    contexts.append(context)\n","                    questions.append(question)\n","                    answers.append(answer)\n","\n","        if num_groups != -1:\n","          num_groups -= 1\n","    # return formatted data lists\n","    return contexts, questions, answers"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:10:44.710184Z","iopub.status.busy":"2022-03-05T16:10:44.709337Z","iopub.status.idle":"2022-03-05T16:10:46.766879Z","shell.execute_reply":"2022-03-05T16:10:46.766146Z","shell.execute_reply.started":"2022-03-05T16:10:44.710131Z"},"executionInfo":{"elapsed":3453,"status":"ok","timestamp":1646319017037,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"qt0-EbDO8ZV1","trusted":true},"outputs":[],"source":["# execute our red SQuAD function for training and validation sets\n","\n","num_groups = -1 # take the first 100 group of contexts/questions/answers from squad\n","\n","train_contexts, train_questions, train_answers = read_squad(Location_squad_train2, num_groups)\n","val_contexts, val_questions, val_answers = read_squad(Location_squad_dev2, num_groups)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:10:46.768696Z","iopub.status.busy":"2022-03-05T16:10:46.768452Z","iopub.status.idle":"2022-03-05T16:10:46.775492Z","shell.execute_reply":"2022-03-05T16:10:46.774815Z","shell.execute_reply.started":"2022-03-05T16:10:46.768662Z"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1646319017038,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"6jBn0JaNd_DE","outputId":"ba8de523-6680-42a3-fc05-be15d87cc1d3","trusted":true},"outputs":[{"data":{"text/plain":["(130319, 130319, 130319)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["len(train_contexts), len(train_questions), len(train_answers)   # if we have 1 group we have several questions/answers from the same context"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:10:48.496468Z","iopub.status.busy":"2022-03-05T16:10:48.495924Z","iopub.status.idle":"2022-03-05T16:10:48.502150Z","shell.execute_reply":"2022-03-05T16:10:48.501269Z","shell.execute_reply.started":"2022-03-05T16:10:48.496430Z"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1646319017038,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"syXRCx597hQ5","outputId":"66703ac9-5c17-4ffa-8833-377e37a2d106","trusted":true},"outputs":[{"data":{"text/plain":["(26232, 26232, 26232)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["len(val_contexts), len(val_questions), len(val_answers)   # if we have 1 group we have several questions/answers from the same context"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:10:50.131620Z","iopub.status.busy":"2022-03-05T16:10:50.131082Z","iopub.status.idle":"2022-03-05T16:10:50.137716Z","shell.execute_reply":"2022-03-05T16:10:50.137038Z","shell.execute_reply.started":"2022-03-05T16:10:50.131585Z"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1646319018156,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"zFxCdBC3kAVO","outputId":"daa58717-473c-47bb-b449-4f74fc749be8","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n","When did Beyonce start becoming popular?\n","{'text': 'in the late 1990s', 'answer_start': 269}\n","\n","\n","\n","Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n","What areas did Beyonce compete in when she was growing up?\n","{'text': 'singing and dancing', 'answer_start': 207}\n"]}],"source":["# Test our data\n","print(train_contexts[0])\n","print(train_questions[0])\n","print(train_answers[0])\n","print('\\n\\n')\n","print(train_contexts[1])\n","print(train_questions[1])\n","print(train_answers[1])"]},{"cell_type":"markdown","metadata":{"id":"U_k4d23gk0le"},"source":["Contexts for the first 2 questions seems to be the same, but question/answer is different, so we are right."]},{"cell_type":"markdown","metadata":{"id":"1E4NK8JQCzRI"},"source":["## Indicate the start and the end of each answer within the context"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:10:51.594790Z","iopub.status.busy":"2022-03-05T16:10:51.593926Z","iopub.status.idle":"2022-03-05T16:10:51.708002Z","shell.execute_reply":"2022-03-05T16:10:51.707137Z","shell.execute_reply.started":"2022-03-05T16:10:51.594740Z"},"executionInfo":{"elapsed":348,"status":"ok","timestamp":1646319020162,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"hCPZjE68C7E4","trusted":true},"outputs":[],"source":["def add_end_idx(answers, contexts):\n","    # loop through each answer-context pair\n","    for answer, context in zip(answers, contexts):\n","        # gold_text refers to the answer we are expecting to find in context\n","        gold_text = answer['text']\n","        # we already know the start index\n","        start_idx = answer['answer_start']\n","        # and ideally this would be the end index...\n","        end_idx = start_idx + len(gold_text)\n","\n","        # ...however, sometimes squad answers are off by a character or two\n","        if context[start_idx:end_idx] == gold_text:\n","            # if the answer is not off :)\n","            answer['answer_end'] = end_idx\n","        else:\n","            # this means the answer is off by 1-2 tokens\n","            for n in [1, 2]:\n","                if context[start_idx-n:end_idx-n] == gold_text:\n","                    answer['answer_start'] = start_idx - n\n","                    answer['answer_end'] = end_idx - n\n","            \n","# and apply the function to our two answer lists\n","add_end_idx(train_answers, train_contexts)\n","add_end_idx(val_answers, val_contexts)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:10:53.619998Z","iopub.status.busy":"2022-03-05T16:10:53.619743Z","iopub.status.idle":"2022-03-05T16:10:53.625869Z","shell.execute_reply":"2022-03-05T16:10:53.625186Z","shell.execute_reply.started":"2022-03-05T16:10:53.619970Z"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1646319021585,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"1C43q5VKFheJ","outputId":"26c90435-c94c-48e9-f5f7-2c973083b197","trusted":true},"outputs":[{"data":{"text/plain":["[{'text': 'in the late 1990s', 'answer_start': 269, 'answer_end': 286},\n"," {'text': 'singing and dancing', 'answer_start': 207, 'answer_end': 226},\n"," {'text': '2003', 'answer_start': 526, 'answer_end': 530},\n"," {'text': 'Houston, Texas', 'answer_start': 166, 'answer_end': 180},\n"," {'text': 'late 1990s', 'answer_start': 276, 'answer_end': 286}]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["train_answers[:5]"]},{"cell_type":"markdown","metadata":{"id":"NJmOe9lDxN-G"},"source":["# Tokenization function for Bert and DistilBert"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:10:55.191615Z","iopub.status.busy":"2022-03-05T16:10:55.190774Z","iopub.status.idle":"2022-03-05T16:10:55.201562Z","shell.execute_reply":"2022-03-05T16:10:55.200631Z","shell.execute_reply.started":"2022-03-05T16:10:55.191558Z"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1646319023411,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"3R5GTtJAxKen","trusted":true},"outputs":[],"source":["def add_token_positions(encodings, answers):\n","    # initialize lists to contain the token indices of answer start/end\n","    start_positions = []\n","    end_positions = []\n","    for i in range(len(answers)):\n","        # append start/end token position using char_to_token method\n","        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n","        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n","\n","        # if start position is None, the answer passage has been truncated\n","        if start_positions[-1] is None:\n","            start_positions[-1] = tokenizer.model_max_length\n","        # end position cannot be found, char_to_token found space, so shift position until found\n","        shift = 1\n","        while end_positions[-1] is None:\n","            end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] - shift)\n","            shift += 1\n","    # update our encodings object with the new token-based start/end positions\n","    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})"]},{"cell_type":"markdown","metadata":{"id":"TbfrSLIIwofa"},"source":["# Initializing the Dataset Squad "]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:10:56.840303Z","iopub.status.busy":"2022-03-05T16:10:56.839741Z","iopub.status.idle":"2022-03-05T16:10:56.845693Z","shell.execute_reply":"2022-03-05T16:10:56.844688Z","shell.execute_reply.started":"2022-03-05T16:10:56.840263Z"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1646319024685,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"QCoNss_DxZtn","trusted":true},"outputs":[],"source":["import torch\n","\n","class SquadDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","\n","    def __getitem__(self, idx):\n","        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","\n","    def __len__(self):\n","        return len(self.encodings.input_ids)"]},{"cell_type":"markdown","metadata":{"id":"wINoIblnnjzu"},"source":["# DistilBert model"]},{"cell_type":"markdown","metadata":{"id":"EXTwNUz2E8_N"},"source":["## Tokenization with DistilBertTokenizerFast and Encoding the data"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T09:39:07.442059Z","iopub.status.busy":"2022-03-05T09:39:07.441775Z","iopub.status.idle":"2022-03-05T09:39:14.286962Z","shell.execute_reply":"2022-03-05T09:39:14.286279Z","shell.execute_reply.started":"2022-03-05T09:39:07.442027Z"},"executionInfo":{"elapsed":1231,"status":"ok","timestamp":1646319027624,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"LKSo4zpIDLir","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a9ee60404f845d49fa4f37f48071542","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76ddc6678af64d058e6cb86ce5cef4cd","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"84035f118eb248bab9dcc0e49d1e0058","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7363e29b5f10423cb7cb9c8719769716","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import DistilBertTokenizerFast\n","from transformers import AutoTokenizer, BertForQuestionAnswering\n","\n","# initialize the tokenizer\n","\n","# first way\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased', \n","                                                    do_lower_case=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T09:39:14.288826Z","iopub.status.busy":"2022-03-05T09:39:14.288478Z","iopub.status.idle":"2022-03-05T09:40:35.920273Z","shell.execute_reply":"2022-03-05T09:40:35.919357Z","shell.execute_reply.started":"2022-03-05T09:39:14.288788Z"},"executionInfo":{"elapsed":70308,"status":"ok","timestamp":1646319098197,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"wY7bHhV6FLBb","trusted":true},"outputs":[],"source":["# tokenize\n","train_encodings = tokenizer(train_contexts, \n","                            train_questions, \n","                            truncation=True,\n","                            max_length=324, \n","                            padding=True )\n","\n","\n","val_encodings = tokenizer(val_contexts, \n","                          val_questions, \n","                          truncation=True, \n","                          max_length=324,\n","                          padding=True )"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T09:40:35.921906Z","iopub.status.busy":"2022-03-05T09:40:35.921666Z","iopub.status.idle":"2022-03-05T09:40:37.212738Z","shell.execute_reply":"2022-03-05T09:40:37.212021Z","shell.execute_reply.started":"2022-03-05T09:40:35.921875Z"},"executionInfo":{"elapsed":6037,"status":"ok","timestamp":1646319104226,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"my_6n748HC_x","trusted":true},"outputs":[],"source":["# apply function to our data\n","add_token_positions(train_encodings, train_answers)\n","add_token_positions(val_encodings, val_answers)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T09:40:37.215048Z","iopub.status.busy":"2022-03-05T09:40:37.214782Z","iopub.status.idle":"2022-03-05T09:40:37.221481Z","shell.execute_reply":"2022-03-05T09:40:37.220609Z","shell.execute_reply.started":"2022-03-05T09:40:37.215013Z"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1646319104227,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"ltMCAGz3KUgR","outputId":"757cfb63-bae0-46e0-a193-dc3031078511","trusted":true},"outputs":[{"data":{"text/plain":["dict_keys(['input_ids', 'attention_mask', 'start_positions', 'end_positions'])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["train_encodings.keys()"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T09:40:37.223387Z","iopub.status.busy":"2022-03-05T09:40:37.222674Z","iopub.status.idle":"2022-03-05T09:40:37.230138Z","shell.execute_reply":"2022-03-05T09:40:37.229191Z","shell.execute_reply.started":"2022-03-05T09:40:37.223348Z"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1646319104227,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"SwyHBw55LX4y","trusted":true},"outputs":[],"source":["# build datasets for both our training and validation sets\n","train_dataset = SquadDataset(train_encodings)\n","val_dataset = SquadDataset(val_encodings)"]},{"cell_type":"markdown","metadata":{"id":"Mzb4CoNugL0p"},"source":["## Dataloaders\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T09:40:37.232061Z","iopub.status.busy":"2022-03-05T09:40:37.231613Z","iopub.status.idle":"2022-03-05T09:40:37.239625Z","shell.execute_reply":"2022-03-05T09:40:37.238695Z","shell.execute_reply.started":"2022-03-05T09:40:37.232018Z"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1646319104227,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"n7nz06rSgLUp","trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","# initialize data loader for training data\n","BATCH_SIZE = 8\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"]},{"cell_type":"markdown","metadata":{"id":"jTWQSRCH0XDJ"},"source":["## Define the DistilBert model"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T09:40:37.242839Z","iopub.status.busy":"2022-03-05T09:40:37.242629Z","iopub.status.idle":"2022-03-05T09:40:55.094921Z","shell.execute_reply":"2022-03-05T09:40:55.094182Z","shell.execute_reply.started":"2022-03-05T09:40:37.242815Z"},"executionInfo":{"elapsed":1437,"status":"ok","timestamp":1646319105655,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"tYD4C0bn0RmZ","outputId":"e8fbb05f-2b06-4317-baa2-8531259808f4","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6661e13e03c44d8aa0e41429c4b430e8","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight']\n","- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import DistilBertForQuestionAnswering \n","\n","model_DistilBert = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased').to(device)"]},{"cell_type":"markdown","metadata":{"id":"_ccskoxvyBZj"},"source":["# Evaluation from https://rajpurkar.github.io/SQuAD-explorer/"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:11:04.040890Z","iopub.status.busy":"2022-03-05T16:11:04.040630Z","iopub.status.idle":"2022-03-05T16:11:04.049720Z","shell.execute_reply":"2022-03-05T16:11:04.048950Z","shell.execute_reply.started":"2022-03-05T16:11:04.040861Z"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1646319106288,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"xCRbnuBA1Z9_","trusted":true},"outputs":[],"source":["# Function for exc\n","def extract_tokens(compressed_tokens, positions):\n","  tokens = dict()\n","\n","  sp = positions[0]     # start positions for each answer\n","  ep = positions[1]     # end positions for each answer (it's not actually the start position, is the first token for the answer)\n","  \n","  num_answers = len(sp)\n","  index = 0\n","  max_length = len(compressed_tokens['input_ids'][index])   # this is the max_length from tokenizer !\n","  \n","  for start, end in zip(sp, ep):  \n","    tokens[index] = []          # we will fill this list with tokens for each question\n","    \n","    start = int(start)\n","    end = int(end)\n","\n","    if start > end:\n","      # print('index: ', index)\n","      if end <= max_length:    # we have to check it if we have argument max_length in tokenizer\n","        tokens[index].append(tokenizer.decode(compressed_tokens['input_ids'][index][end]))\n","      if start <= max_length :\n","        tokens[index].append(tokenizer.decode(compressed_tokens['input_ids'][index][start]))\n","    else:\n","      for i in range(start, end+1):\n","        # print(i)\n","        if i <= max_length:\n","          tokens[index].append(tokenizer.decode(compressed_tokens['input_ids'][index][i]))\n","    index += 1\n","\n","  return tokens"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:11:05.413883Z","iopub.status.busy":"2022-03-05T16:11:05.413359Z","iopub.status.idle":"2022-03-05T16:11:05.430994Z","shell.execute_reply":"2022-03-05T16:11:05.429982Z","shell.execute_reply.started":"2022-03-05T16:11:05.413846Z"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1646319106288,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"OH152hxowJX9","trusted":true},"outputs":[],"source":["import argparse\n","import collections\n","import json\n","import numpy as np\n","import os\n","import re\n","import string\n","import sys\n","\n","\n","def normalize_answer(s):\n","  \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n","  def remove_articles(text):\n","    regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n","    return re.sub(regex, ' ', text)\n","  def white_space_fix(text):\n","    return ' '.join(text.split())\n","  def remove_punc(text):\n","    exclude = set(string.punctuation)\n","    return ''.join(ch for ch in text if ch not in exclude)\n","  def lower(text):\n","    return text.lower()\n","  return white_space_fix(remove_articles(remove_punc(lower(s))))\n","\n","  \n","def get_tokens(s):\n","  if not s: return []\n","  return normalize_answer(s).split()\n","\n","\n","\n","def compute_f1(a_gold, a_pred):\n","    gold_toks = get_tokens(a_gold)\n","    pred_toks = get_tokens(a_pred)\n","    common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n","    num_same = sum(common.values())\n","    if len(gold_toks) == 0 or len(pred_toks) == 0:\n","      # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n","      return int(gold_toks == pred_toks)\n","    if num_same == 0:\n","      return 0\n","    precision = 1.0 * num_same / len(pred_toks)\n","    recall = 1.0 * num_same / len(gold_toks)\n","    f1 = (2 * precision * recall) / (precision + recall)\n","    return f1\n","\n","\n","def compute_f1_score(truth_answers, pred_answers):\n","    num_answers = len(truth_answers)   # number of answers for batch ( == batch_size)\n","    total_f1_score = 0\n","\n","    for curr_answer in range(0, num_answers):    # for each answer compute f1 score\n","      a_gold = ' '.join(truth_answers[curr_answer])     # get the current truth answer\n","      a_pred = ' '.join(pred_answers[curr_answer])      # get the current predicted answer\n","\n","      total_f1_score += compute_f1(a_gold, a_pred)\n","\n","    return total_f1_score / num_answers\n","\n","\n","def compute_exact(a_gold, a_pred):\n","  return int(normalize_answer(a_gold) == normalize_answer(a_pred))\n","\n","\n","def compute_exact_score(truth_answers, pred_answers):\n","    num_answers = len(truth_answers)   # number of answers for batch ( == batch_size)\n","    total_exact_score = 0\n","\n","    for curr_answer in range(0, num_answers):    # for each answer compute f1 score\n","      a_gold = ' '.join(truth_answers[curr_answer])     # get the current truth answer\n","      a_pred = ' '.join(pred_answers[curr_answer])      # get the current predicted answer\n","\n","      total_exact_score += compute_exact(a_gold, a_pred)\n","\n","    return total_exact_score / num_answers\n","\n"]},{"cell_type":"markdown","metadata":{"id":"cxsPLsYPxz9J"},"source":["## Fine-tuning DistilBert model"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T09:40:55.133187Z","iopub.status.busy":"2022-03-05T09:40:55.132661Z","iopub.status.idle":"2022-03-05T11:14:38.859213Z","shell.execute_reply":"2022-03-05T11:14:38.857630Z","shell.execute_reply.started":"2022-03-05T09:40:55.133150Z"},"id":"U0c8f_JQxy-5","outputId":"66e97f92-22d3-4b37-bfec-0375bbc48c71","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch: 1: 100%|██████████| 16290/16290 [43:51<00:00,  6.19it/s, training_loss=1.466]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1 | Train Loss: 1.466 | Val Loss: 1.231 | Train Acc: 58.80% | Val Acc: 64.33% | Exact Score: 56.48% | F1 Score: 72.99%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch: 2: 100%|██████████| 16290/16290 [43:51<00:00,  6.19it/s, training_loss=0.942]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2 | Train Loss: 0.942 | Val Loss: 1.256 | Train Acc: 71.27% | Val Acc: 65.11% | Exact Score: 57.91% | F1 Score: 74.23%\n"]}],"source":["from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","# initialize adam optimizer with weight decay (reduces chance of overfitting)\n","optim = torch.optim.AdamW(model_DistilBert.parameters(), lr=2e-5)\n","\n","epochs = 2\n","\n","\n","train_losses = []\n","test_losses = []\n","\n","for epoch in range(epochs):\n","    \n","    train_loss = []\n","    test_loss = []\n","    acc_train = []\n","    acc_test = []\n","\n","    # for compute f1\n","    pred_start = []\n","    pred_end = []\n","    true_start = []\n","    true_end = []\n","    f1_scores = []\n","    exact_scores = []\n","\n","    model_DistilBert.train()   # set model to train mode\n","    with torch.set_grad_enabled(True):\n","      # setup loop (we use tqdm for the progress bar)\n","      progress_bar = tqdm(train_loader, f\"Epoch: {epoch+1}\")\n","      for batch in progress_bar:\n","          # initialize calculated gradients (from prev step)\n","          optim.zero_grad()\n","\n","          # pull all the tensor batches required for training\n","          input_ids = batch['input_ids'].to(device)\n","          attention_mask = batch['attention_mask'].to(device)\n","          start_positions = batch['start_positions'].to(device)\n","          end_positions = batch['end_positions'].to(device)\n","\n","          # print('start_positions', start_positions)\n","          \n","          # train model on batch and return outputs (incl. loss)\n","          outputs = model_DistilBert(input_ids, attention_mask=attention_mask,\n","                          start_positions=start_positions,\n","                          end_positions=end_positions)\n","          \n","          # get the predictions\n","          start_pred = torch.argmax(outputs['start_logits'], dim=1)\n","          end_pred = torch.argmax(outputs['end_logits'], dim=1)\n","\n","          \n","          # extract loss\n","          loss = outputs[0]\n","\n","          # calculate loss for every parameter that needs grad update\n","          loss.backward()\n","          # update parameters\n","          optim.step()\n","          train_loss.append(loss.item())\n","\n","          # calculate accuracy for both and append to accuracy list\n","          acc_train.append(((start_pred == start_positions).sum()/len(start_pred)).item())\n","          acc_train.append(((end_pred == end_positions).sum()/len(end_pred)).item())\n","\n","          # print relevant info to progress bar\n","          # progress_bar.set_description(f'Epoch {epoch+1}')\n","          progress_bar.set_postfix({'training_loss': '{:.3f}'.format(np.mean(train_loss))})\n","    \n","    # get the average loss\n","    train_loss_temp = np.mean(train_loss)\n","    train_losses.append(train_loss_temp)\n","    \n","    acc_train_temp = np.mean(acc_train)   # average accuracy of the train set\n","\n","\n","    model_DistilBert.eval()  # switch model out of training mode\n","    for batch in val_loader:\n","        # we don't need to calculate gradients as we're not training\n","        with torch.no_grad():\n","            # pull all the tensor batches required for training\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","\n","            # we will use true positions for accuracy calc\n","            start_true = batch['start_positions'].to(device)\n","            end_true = batch['end_positions'].to(device)\n","\n","\n","            # train model on batch and return outputs (incl. loss)\n","            outputs = model_DistilBert(input_ids, attention_mask=attention_mask,\n","                                start_positions=start_true,\n","                                end_positions=end_true)\n","            \n","            # extract loss\n","            loss = outputs[0]\n","\n","            # pull prediction tensors out and argmax to get predicted tokens\n","            start_pred = torch.argmax(outputs['start_logits'], dim=1)\n","            end_pred = torch.argmax(outputs['end_logits'], dim=1)\n","\n","            # ~~~ Compute F1 score with tokens ~~~~\n","            # extract truth tokens\n","            truth_positions = [start_true.detach().cpu(), end_true.detach().cpu()]\n","            truth_tokens = extract_tokens(batch, truth_positions)\n","\n","            # extract predicted tokens\n","            pred_positions = [start_pred, end_pred]\n","            pred_tokens = extract_tokens(batch, pred_positions)\n","\n","            f1_scores.append (compute_f1_score(truth_tokens, pred_tokens))\n","            exact_scores.append(compute_exact_score(truth_tokens, pred_tokens))\n","                      \n","            test_loss.append(loss.item())\n","\n","\n","\n","            # calculate accuracy for both and append to accuracy list\n","            acc_test.append(((start_pred == start_true).sum()/len(start_pred)).item())\n","            acc_test.append(((end_pred == end_true).sum()/len(end_pred)).item())\n","            \n","    # calculate the average test loss\n","    test_loss_temp = np.mean(test_loss)\n","    test_losses.append(test_loss_temp)\n","\n","    # calculate average accuracy in total\n","    acc_test_temp = np.mean(acc_test)\n","    f1_score_temp = np.mean(f1_scores)\n","    exact_score_temp = np.mean(exact_scores)\n","\n","    \n","\n","    tqdm.write(f'''Epoch: {epoch+1} | Train Loss: {train_loss_temp:.3f} | Val Loss: {test_loss_temp:.3f} | Train Acc: {acc_train_temp*100:.2f}% | Val Acc: {acc_test_temp*100:.2f}% | Exact Score: {exact_score_temp * 100:.2f}% | F1 Score: {f1_score_temp * 100:.2f}%''')\n"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T11:14:38.861055Z","iopub.status.busy":"2022-03-05T11:14:38.860777Z","iopub.status.idle":"2022-03-05T11:14:38.867503Z","shell.execute_reply":"2022-03-05T11:14:38.866631Z","shell.execute_reply.started":"2022-03-05T11:14:38.861017Z"},"executionInfo":{"elapsed":432,"status":"ok","timestamp":1646302428619,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"QY1fzIueRVG7","outputId":"0414c18e-9a22-4513-d05e-553cf75d18e3","trusted":true},"outputs":[{"data":{"text/plain":["{'text': '10th and 11th centuries', 'answer_start': 94, 'answer_end': 117}"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["val_answers[4]"]},{"cell_type":"markdown","metadata":{"id":"myMTabFdI1-O"},"source":["## Plot train and validation loss for DistilBert model"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T11:14:38.869313Z","iopub.status.busy":"2022-03-05T11:14:38.869025Z","iopub.status.idle":"2022-03-05T11:14:39.134858Z","shell.execute_reply":"2022-03-05T11:14:39.134080Z","shell.execute_reply.started":"2022-03-05T11:14:38.869275Z"},"executionInfo":{"elapsed":348,"status":"ok","timestamp":1645975754701,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09665955934739897822"},"user_tz":-120},"id":"vViQiqUfI0w-","outputId":"44ec72ae-baa2-4199-e9bc-3e65de944650","trusted":true},"outputs":[{"data":{"text/plain":["<matplotlib.legend.Legend at 0x7fd9fa610910>"]},"execution_count":23,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 864x360 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["#Plotting loss vs epochs.\n","plt.figure(figsize=(12, 5))\n","\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.plot(train_losses, label='Train Loss')\n","plt.plot(test_losses, label='Test Loss')\n","plt.legend(frameon=False)"]},{"cell_type":"markdown","metadata":{"id":"urr1hnYZnqvu"},"source":["# Bert model"]},{"cell_type":"markdown","metadata":{"id":"TNcxLRygxqQN"},"source":["## Tokenization with BertTokenizer and Encoding the data"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:10:13.688511Z","iopub.status.busy":"2022-03-05T16:10:13.687860Z","iopub.status.idle":"2022-03-05T16:10:21.329027Z","shell.execute_reply":"2022-03-05T16:10:21.328273Z","shell.execute_reply.started":"2022-03-05T16:10:13.688382Z"},"id":"cBwTsUHfxqQN","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8804b53314be4238888f94ecf8843e25","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a4f8994508c4d919c581ca63db7f0e8","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f783835234da48e58d0d6d71b4f582ed","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c68262226fb04324b9f81da88da883a9","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoTokenizer, BertForQuestionAnswering\n","\n","# initialize the tokenizer\n","\n","# Second way\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\",\n","                                                      do_lower_case=True)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:11:24.754709Z","iopub.status.busy":"2022-03-05T16:11:24.754445Z","iopub.status.idle":"2022-03-05T16:12:53.267944Z","shell.execute_reply":"2022-03-05T16:12:53.267171Z","shell.execute_reply.started":"2022-03-05T16:11:24.754681Z"},"id":"c64RF4C9xqQN","trusted":true},"outputs":[],"source":["# tokenize\n","train_encodings = tokenizer(train_contexts, \n","                            train_questions, \n","                            truncation=True,\n","                            max_length=324, \n","                            padding=True)\n","\n","\n","val_encodings = tokenizer(val_contexts, \n","                          val_questions, \n","                          truncation=True, \n","                          max_length=324,\n","                          padding=True)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:12:53.269722Z","iopub.status.busy":"2022-03-05T16:12:53.269474Z","iopub.status.idle":"2022-03-05T16:12:59.939669Z","shell.execute_reply":"2022-03-05T16:12:59.938927Z","shell.execute_reply.started":"2022-03-05T16:12:53.269688Z"},"executionInfo":{"elapsed":415,"status":"ok","timestamp":1646169231081,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"YMpeH2lmxqQO","outputId":"80e38e81-b90e-4458-846a-44e3b70bb9b9","trusted":true},"outputs":[{"data":{"text/plain":["'[CLS] the normans ( norman : nourmands ; french : normands ; latin : normanni ) were the people who in the 10th and 11th centuries gave their name to normandy, a region in france. they were descended from norse ( \" norman \" comes from \" norseman \" ) raiders and pirates from denmark, iceland and norway who, under their leader rollo, agreed to swear fealty to king charles iii of west francia. through generations of assimilation and mixing with the native frankish and roman - gaulish populations, their descendants would gradually merge with the carolingian - based cultures of west francia. the distinct cultural and ethnic identity of the normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries. [SEP] in what country is normandy located? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(val_encodings['input_ids'][0])[:]"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:12:59.941689Z","iopub.status.busy":"2022-03-05T16:12:59.940952Z","iopub.status.idle":"2022-03-05T16:13:00.977906Z","shell.execute_reply":"2022-03-05T16:13:00.977165Z","shell.execute_reply.started":"2022-03-05T16:12:59.941647Z"},"id":"XgYvuBFDxqQO","trusted":true},"outputs":[],"source":["# apply function to our data\n","add_token_positions(train_encodings, train_answers)\n","add_token_positions(val_encodings, val_answers)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:13:00.980584Z","iopub.status.busy":"2022-03-05T16:13:00.980284Z","iopub.status.idle":"2022-03-05T16:13:00.985840Z","shell.execute_reply":"2022-03-05T16:13:00.985174Z","shell.execute_reply.started":"2022-03-05T16:13:00.980548Z"},"executionInfo":{"elapsed":440,"status":"ok","timestamp":1646059558308,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09665955934739897822"},"user_tz":-120},"id":"KttsM_FNxqQO","outputId":"f04e581f-1a47-41ea-de42-113554539290","trusted":true},"outputs":[{"data":{"text/plain":["dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["train_encodings.keys()"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:13:00.987690Z","iopub.status.busy":"2022-03-05T16:13:00.987228Z","iopub.status.idle":"2022-03-05T16:13:00.995519Z","shell.execute_reply":"2022-03-05T16:13:00.994688Z","shell.execute_reply.started":"2022-03-05T16:13:00.987652Z"},"id":"KjdxMAQexqQO","trusted":true},"outputs":[],"source":["# build datasets for both our training and validation sets\n","train_dataset = SquadDataset(train_encodings)\n","val_dataset = SquadDataset(val_encodings)"]},{"cell_type":"markdown","metadata":{"id":"JV_vTqE0xqQO"},"source":["## Dataloaders\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:13:00.997095Z","iopub.status.busy":"2022-03-05T16:13:00.996772Z","iopub.status.idle":"2022-03-05T16:13:01.004715Z","shell.execute_reply":"2022-03-05T16:13:01.004029Z","shell.execute_reply.started":"2022-03-05T16:13:00.997062Z"},"id":"hWycUF4BxqQO","trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","# initialize data loader for training data\n","BATCH_SIZE = 8\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:13:01.006710Z","iopub.status.busy":"2022-03-05T16:13:01.005968Z","iopub.status.idle":"2022-03-05T16:13:28.553285Z","shell.execute_reply":"2022-03-05T16:13:28.552440Z","shell.execute_reply.started":"2022-03-05T16:13:01.006672Z"},"executionInfo":{"elapsed":19487,"status":"ok","timestamp":1646168767823,"user":{"displayName":"Nick","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09933765762641469766"},"user_tz":-120},"id":"mvAQc9WnxqQO","outputId":"bf131940-106d-4c7d-862a-0e3862501d1a","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e5e752abe644801abc76054b1a0c176","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import BertForQuestionAnswering\n","\n","\n","model_Bert = BertForQuestionAnswering.from_pretrained('bert-base-uncased').to(device)"]},{"cell_type":"markdown","metadata":{"id":"3Fv7o5F4xqQO"},"source":["## Fine-tuning Bert model"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T16:14:28.919861Z","iopub.status.busy":"2022-03-05T16:14:28.919576Z","iopub.status.idle":"2022-03-05T19:13:37.248342Z","shell.execute_reply":"2022-03-05T19:13:37.247585Z","shell.execute_reply.started":"2022-03-05T16:14:28.919830Z"},"id":"MfEbRGRaxqQO","outputId":"a0cb0bb3-300f-4137-bf2a-64fc67c47e10","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch: 1: 100%|██████████| 16290/16290 [1:23:50<00:00,  3.24it/s, training_loss=1.295]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1 | Train Loss: 1.295 | Val Loss: 1.156 | Train Acc: 63.04% | Val Acc: 67.19% | Exact Score: 59.61% | F1 Score: 76.26%\n"]},{"name":"stderr","output_type":"stream","text":["Epoch: 2: 100%|██████████| 16290/16290 [1:23:54<00:00,  3.24it/s, training_loss=0.824]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2 | Train Loss: 0.824 | Val Loss: 1.161 | Train Acc: 74.58% | Val Acc: 67.83% | Exact Score: 60.63% | F1 Score: 76.74%\n"]}],"source":["from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","# initialize adam optimizer with weight decay (reduces chance of overfitting)\n","optim = torch.optim.AdamW(model_Bert.parameters(), lr=2e-5)\n","\n","epochs = 2\n","\n","\n","train_losses = []\n","test_losses = []\n","\n","for epoch in range(epochs):\n","    \n","    train_loss = []\n","    test_loss = []\n","    acc_train = []\n","    acc_test = []\n","\n","    # for compute f1\n","    pred_start = []\n","    pred_end = []\n","    true_start = []\n","    true_end = []\n","    f1_scores = []\n","    exact_scores = []\n","\n","    model_Bert.train()   # set model to train mode\n","    with torch.set_grad_enabled(True):\n","      # setup loop (we use tqdm for the progress bar)\n","      progress_bar = tqdm(train_loader, f\"Epoch: {epoch+1}\")\n","      for batch in progress_bar:\n","          # initialize calculated gradients (from prev step)\n","          optim.zero_grad()\n","\n","          # pull all the tensor batches required for training\n","          input_ids = batch['input_ids'].to(device)\n","          attention_mask = batch['attention_mask'].to(device)\n","          start_positions = batch['start_positions'].to(device)\n","          end_positions = batch['end_positions'].to(device)\n","\n","          # print('start_positions', start_positions)\n","          \n","          # train model on batch and return outputs (incl. loss)\n","          outputs = model_Bert(input_ids, attention_mask=attention_mask,\n","                          start_positions=start_positions,\n","                          end_positions=end_positions)\n","          \n","          # get the predictions\n","          start_pred = torch.argmax(outputs['start_logits'], dim=1)\n","          end_pred = torch.argmax(outputs['end_logits'], dim=1)\n","\n","          \n","          # extract loss\n","          loss = outputs[0]\n","\n","          # calculate loss for every parameter that needs grad update\n","          loss.backward()\n","          # update parameters\n","          optim.step()\n","          train_loss.append(loss.item())\n","\n","          # calculate accuracy for both and append to accuracy list\n","          acc_train.append(((start_pred == start_positions).sum()/len(start_pred)).item())\n","          acc_train.append(((end_pred == end_positions).sum()/len(end_pred)).item())\n","\n","          # print relevant info to progress bar\n","          # progress_bar.set_description(f'Epoch {epoch+1}')\n","          progress_bar.set_postfix({'training_loss': '{:.3f}'.format(np.mean(train_loss))})\n","    \n","    # get the average loss\n","    train_loss_temp = np.mean(train_loss)\n","    train_losses.append(train_loss_temp)\n","    \n","    acc_train_temp = np.mean(acc_train)   # average accuracy of the train set\n","\n","\n","    model_Bert.eval()  # switch model out of training mode\n","    for batch in val_loader:\n","        # we don't need to calculate gradients as we're not training\n","        with torch.no_grad():\n","            # pull all the tensor batches required for training\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","\n","            # we will use true positions for accuracy calc\n","            start_true = batch['start_positions'].to(device)\n","            end_true = batch['end_positions'].to(device)\n","\n","\n","            # train model on batch and return outputs (incl. loss)\n","            outputs = model_Bert(input_ids, attention_mask=attention_mask,\n","                                start_positions=start_true,\n","                                end_positions=end_true)\n","            \n","            # extract loss\n","            loss = outputs[0]\n","\n","            # pull prediction tensors out and argmax to get predicted tokens\n","            start_pred = torch.argmax(outputs['start_logits'], dim=1)\n","            end_pred = torch.argmax(outputs['end_logits'], dim=1)\n","\n","            # ~~~ Compute F1 score with tokens ~~~~\n","            # extract truth tokens\n","            truth_positions = [start_true.detach().cpu(), end_true.detach().cpu()]\n","            truth_tokens = extract_tokens(batch, truth_positions)\n","\n","            # extract predicted tokens\n","            pred_positions = [start_pred, end_pred]\n","            pred_tokens = extract_tokens(batch, pred_positions)\n","\n","            f1_scores.append (compute_f1_score(truth_tokens, pred_tokens))\n","            exact_scores.append(compute_exact_score(truth_tokens, pred_tokens))\n","                      \n","            test_loss.append(loss.item())\n","\n","\n","\n","            # calculate accuracy for both and append to accuracy list\n","            acc_test.append(((start_pred == start_true).sum()/len(start_pred)).item())\n","            acc_test.append(((end_pred == end_true).sum()/len(end_pred)).item())\n","            \n","    # calculate the average test loss\n","    test_loss_temp = np.mean(test_loss)\n","    test_losses.append(test_loss_temp)\n","\n","    # calculate average accuracy in total\n","    acc_test_temp = np.mean(acc_test)\n","    f1_score_temp = np.mean(f1_scores)\n","    exact_score_temp = np.mean(exact_scores)\n","\n","    \n","\n","    tqdm.write(f'''Epoch: {epoch+1} | Train Loss: {train_loss_temp:.3f} | Val Loss: {test_loss_temp:.3f} | Train Acc: {acc_train_temp*100:.2f}% | Val Acc: {acc_test_temp*100:.2f}% | Exact Score: {exact_score_temp * 100:.2f}% | F1 Score: {f1_score_temp * 100:.2f}%''')\n"]},{"cell_type":"markdown","metadata":{"id":"uZU_-gD5xqQP"},"source":["## Plot train and validation loss for Bert model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a7GOtesaxqQP","trusted":true},"outputs":[],"source":["#Plotting loss vs epochs.\n","plt.figure(figsize=(12, 5))\n","\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","\n","plt.plot(train_losses, label='Train Loss')\n","plt.plot(test_losses, label='Test Loss')\n","plt.legend(frameon=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
